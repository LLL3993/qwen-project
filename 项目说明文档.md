# 项目说明文档

### 1.电脑配置：

​		1）硬件配置： 

​				CUDA Version: 12.7

​				GPU：NVIDIA GeForce RTX 4060

​		2）软件配置：

​				python 3.8+

​				PyTorch (适配CUDA 12.7版本)

​				相关依赖包（详见requirements.txt）

### 2.模型下载

​		[通义千问3-0.6B · 模型库](https://www.modelscope.cn/models/Qwen/Qwen3-0.6B)

​		（模型文件较大，未直接包含在项目仓库中）

### 3.使用教程：

​		1）将这个项目从GitHub上下载下来

​		2）将模型下载至本地，保存到一个文件夹里

​		3）将后端代码qwen.py中的模型路径修改成保存的文件夹的路径

​		4）运行qwen.py

​		5）点击web文件夹中的index.html，将其在浏览器中打开

​		6）在“输入古文”框中输入想要解析的古文，点击“解析”按钮，等待解析的结果出现在“解析结果”中

### 4.注意事项

​		1）使用上述电脑配置，要等一会解析结果才会出来（RTX 4060设备约需几分钟，如果换成4090或者更好的显卡性能会好很多）

​		2）使用上述模型，请确保显存至少有2GB的空余

​		3）如果想要使用更好的模型，请确保显存充足，并相应调整代码中的模型加载配置

